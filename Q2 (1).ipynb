{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChC3RF8meAlK"
      },
      "source": [
        "<h1 align=\"center\">Introduction to Machine Learning - 25737-2</h1>\n",
        "<h4 align=\"center\">Dr. R. Amiri</h4>\n",
        "<h4 align=\"center\">Sharif University of Technology, Spring 2024</h4>\n",
        "\n",
        "\n",
        "**<font color='red'>Plagiarism is strongly prohibited!</font>**\n",
        "\n",
        "\n",
        "**Student Name**: Sara Rezanezhad\n",
        "\n",
        "**Student ID**: 99101643\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IraiR0SbeDi_"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRQjwWC3eDnc"
      },
      "source": [
        "**Task:** Implement your own Logistic Regression model, and test it on the given dataset of Logistic_question.csv!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75Jdeu93PUf2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class MyLogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(MyLogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.linear(x))\n",
        "\n",
        "class LogisticRegressionModel:\n",
        "    def __init__(self, input_dim):\n",
        "        self.model = MyLogisticRegression(input_dim).cuda()\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.SGD(self.model.parameters(), lr=0.01)\n",
        "\n",
        "    def fit(self, X_train, y_train, epochs=100):\n",
        "        train_data = TensorDataset(torch.from_numpy(X_train).float().cuda(), torch.from_numpy(y_train).float().view(-1, 1).cuda())\n",
        "        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for inputs, labels in train_loader:\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(torch.from_numpy(X_test).float().cuda())\n",
        "            predictions = (outputs.cpu().numpy() > 0.5).astype(int)\n",
        "        return predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-i-oubUlZ6e"
      },
      "source": [
        "**Task:** Test your model on the given dataset. You must split your data into train and test, with a 0.2 split, then normalize your data using X_train data. Finally, report 4 different evaluation metrics of the model on the test set. (You might want to first make the Target column binary!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KXzIy_2u-pG",
        "outputId": "207945b6-2332-4c49-b961-eee73ea1db23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.94\n",
            "Confusion Matrix:\n",
            "[[ 5  5]\n",
            " [ 0 70]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67        10\n",
            "           1       0.93      1.00      0.97        70\n",
            "\n",
            "    accuracy                           0.94        80\n",
            "   macro avg       0.97      0.75      0.82        80\n",
            "weighted avg       0.94      0.94      0.93        80\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('Logistic_question.csv')\n",
        "\n",
        "# Drop rows with missing values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Define the threshold for converting continuous target variable to binary\n",
        "threshold = 0.5  # Define the threshold value as needed\n",
        "\n",
        "# Convert continuous target variable to a binary one\n",
        "data['Target'] = data['Target'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns='Target')\n",
        "y = data['Target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSGr_G1Idvkh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji0RXNGKv1pa"
      },
      "source": [
        "**Question:** What are each of your used evaluation metrics? And for each one, mention situations in which they convey more data on the model performance in specific tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldveD35twRRZ"
      },
      "source": [
        "**Your answer:**\n",
        "The evaluation metrics used in the code snippet are accuracy, confusion matrix, and classification report.\n",
        "\n",
        "1. **Accuracy**: Accuracy is a common metric used to evaluate classification models. It measures the proportion of correctly classified instances out of the total instances. Accuracy is useful when the classes are balanced and there is no significant class imbalance. However, in cases of imbalanced datasets, accuracy may not provide a complete picture of model performance.\n",
        "\n",
        "2. **Confusion Matrix**: A confusion matrix provides a more detailed breakdown of the model's performance by showing the counts of true positive, true negative, false positive, and false negative predictions. It is particularly useful in tasks where different types of errors have varying levels of importance. For example, in medical diagnosis, false negatives (missing a positive case) may be more critical than false positives.\n",
        "\n",
        "3. **Classification Report**: The classification report includes precision, recall, F1-score, and support for each class in the target variable. Precision measures the proportion of true positive predictions out of all positive predictions, recall measures the proportion of true positive predictions out of all actual positives, and the F1-score is the harmonic mean of precision and recall. The classification report is beneficial when you want to understand the trade-off between precision and recall, especially in imbalanced datasets where one class is more prevalent than the others.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZCeRHZSw-mh"
      },
      "source": [
        "**Task:** Now test the built-in function of Python for Logistic Regression, and report all the same metrics used before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb5lRSQXDLR3",
        "outputId": "fdfdd8f2-a70b-44a2-ce94-4954f2cab2bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.94\n",
            "Confusion Matrix:\n",
            "[[ 5  5]\n",
            " [ 0 70]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67        10\n",
            "           1       0.93      1.00      0.97        70\n",
            "\n",
            "    accuracy                           0.94        80\n",
            "   macro avg       0.97      0.75      0.82        80\n",
            "weighted avg       0.94      0.94      0.93        80\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCvIymmMy_ji"
      },
      "source": [
        "**Question:** Compare your function with the built-in function. On the matters of performance and parameters. Briefly explain what the parameters of the built-in function are and how they affect the model's performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY0ohM16z3De"
      },
      "source": [
        "**Your answer:**\n",
        "When comparing a custom Logistic Regression function with the built-in Logistic Regression function in Python's scikit-learn library, there are several aspects to consider in terms of performance and parameters.\n",
        "\n",
        "Performance:\n",
        "1. **Accuracy**: Both the custom function and the built-in function should provide similar accuracy values if implemented correctly. The accuracy metric measures the overall correctness of the model's predictions.\n",
        "\n",
        "2. **Confusion Matrix and Classification Report**: The confusion matrix and classification report should also be consistent between the custom function and the built-in function, providing insights into the model's performance in terms of true positives, true negatives, false positives, and false negatives, as well as precision, recall, and F1-score.\n",
        "\n",
        "Parameters:\n",
        "The built-in Logistic Regression function in scikit-learn allows for customization through various parameters. Some of the key parameters and their effects on model performance are:\n",
        "\n",
        "1. **penalty**: Determines the regularization term used in the model. Regularization helps prevent overfitting by penalizing large coefficients. The 'l1' penalty uses L1 regularization (lasso), while the 'l2' penalty uses L2 regularization (ridge).\n",
        "\n",
        "2. **C**: Inverse of regularization strength. A smaller value of C indicates stronger regularization, which can help prevent overfitting. Tuning the value of C can impact the model's ability to generalize to unseen data.\n",
        "\n",
        "3. **solver**: Specifies the optimization algorithm used to fit the model. Different solvers are suitable for different types of problems. For example, 'liblinear' is a good choice for small datasets, while 'lbfgs' and 'sag' are suitable for larger datasets.\n",
        "\n",
        "4. **class_weight**: Allows for handling imbalanced datasets by assigning different weights to classes. This parameter can be useful when one class dominates the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClMqoYlr2kr7"
      },
      "source": [
        "# Multinomial Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukvlqDe52xP5"
      },
      "source": [
        "**Task:** Implement your own Multinomial Logistic Regression model. Your model must be able to handle any number of labels!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ir-_hFt286t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MyMultinomialLogisticRegression(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(MyMultinomialLogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "    def loss_function(self, outputs, targets):\n",
        "        loss = F.cross_entropy(outputs, targets)\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X_train, y_train, epochs, lr):\n",
        "        optimizer = optim.SGD(self.parameters(), lr=lr)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = self.forward(X_train)\n",
        "            loss = self.loss_function(outputs, y_train)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        outputs = self.forward(X_test)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        return predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPQ3Rtay3Y2_"
      },
      "source": [
        "**Task:** Test your model on the given dataset. Do the same as the previous part, but here you might want to first make the Target column quantized into $i$ levels. Change $i$ from 2 to 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aP4QJPq29B3",
        "outputId": "f9da1bcb-481e-4b40-efc9-59a32f905c56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.8812591433525085\n",
            "Epoch 10, Loss: 0.7094274759292603\n",
            "Epoch 20, Loss: 0.6008730530738831\n",
            "Epoch 30, Loss: 0.5311353802680969\n",
            "Epoch 40, Loss: 0.48425325751304626\n",
            "Epoch 50, Loss: 0.45115169882774353\n",
            "Epoch 60, Loss: 0.42674511671066284\n",
            "Epoch 70, Loss: 0.408090204000473\n",
            "Epoch 80, Loss: 0.39340636134147644\n",
            "Epoch 90, Loss: 0.3815666735172272\n",
            "Quantization levels: 2, Test Accuracy: 0.0\n",
            "Epoch 0, Loss: 1.4809350967407227\n",
            "Epoch 10, Loss: 1.2940505743026733\n",
            "Epoch 20, Loss: 1.155160665512085\n",
            "Epoch 30, Loss: 1.0545694828033447\n",
            "Epoch 40, Loss: 0.98167484998703\n",
            "Epoch 50, Loss: 0.9279400706291199\n",
            "Epoch 60, Loss: 0.8873610496520996\n",
            "Epoch 70, Loss: 0.8559190034866333\n",
            "Epoch 80, Loss: 0.8309462666511536\n",
            "Epoch 90, Loss: 0.8106552958488464\n",
            "Quantization levels: 3, Test Accuracy: 0.0\n",
            "Epoch 0, Loss: 1.432816505432129\n",
            "Epoch 10, Loss: 1.365410566329956\n",
            "Epoch 20, Loss: 1.3107023239135742\n",
            "Epoch 30, Loss: 1.2659567594528198\n",
            "Epoch 40, Loss: 1.2289838790893555\n",
            "Epoch 50, Loss: 1.1980741024017334\n",
            "Epoch 60, Loss: 1.1719142198562622\n",
            "Epoch 70, Loss: 1.149500846862793\n",
            "Epoch 80, Loss: 1.1300691366195679\n",
            "Epoch 90, Loss: 1.113033413887024\n",
            "Quantization levels: 4, Test Accuracy: 0.0\n",
            "Epoch 0, Loss: 1.6518571376800537\n",
            "Epoch 10, Loss: 1.5772273540496826\n",
            "Epoch 20, Loss: 1.514845848083496\n",
            "Epoch 30, Loss: 1.462793231010437\n",
            "Epoch 40, Loss: 1.4193050861358643\n",
            "Epoch 50, Loss: 1.3828403949737549\n",
            "Epoch 60, Loss: 1.3520985841751099\n",
            "Epoch 70, Loss: 1.326006293296814\n",
            "Epoch 80, Loss: 1.3036906719207764\n",
            "Epoch 90, Loss: 1.284448504447937\n",
            "Quantization levels: 5, Test Accuracy: 0.0\n",
            "Epoch 0, Loss: 1.7137197256088257\n",
            "Epoch 10, Loss: 1.6749204397201538\n",
            "Epoch 20, Loss: 1.640875220298767\n",
            "Epoch 30, Loss: 1.6109203100204468\n",
            "Epoch 40, Loss: 1.5844850540161133\n",
            "Epoch 50, Loss: 1.5610765218734741\n",
            "Epoch 60, Loss: 1.5402711629867554\n",
            "Epoch 70, Loss: 1.5217039585113525\n",
            "Epoch 80, Loss: 1.5050623416900635\n",
            "Epoch 90, Loss: 1.4900785684585571\n",
            "Quantization levels: 6, Test Accuracy: 0.0\n",
            "Epoch 0, Loss: 2.12251877784729\n",
            "Epoch 10, Loss: 2.0595879554748535\n",
            "Epoch 20, Loss: 2.004504919052124\n",
            "Epoch 30, Loss: 1.9562933444976807\n",
            "Epoch 40, Loss: 1.914035439491272\n",
            "Epoch 50, Loss: 1.8769018650054932\n",
            "Epoch 60, Loss: 1.8441604375839233\n",
            "Epoch 70, Loss: 1.8151791095733643\n",
            "Epoch 80, Loss: 1.789414644241333\n",
            "Epoch 90, Loss: 1.7664070129394531\n",
            "Quantization levels: 7, Test Accuracy: 0.0\n",
            "Epoch 0, Loss: 2.5629923343658447\n",
            "Epoch 10, Loss: 2.475381374359131\n",
            "Epoch 20, Loss: 2.395246982574463\n",
            "Epoch 30, Loss: 2.322223424911499\n",
            "Epoch 40, Loss: 2.255889415740967\n",
            "Epoch 50, Loss: 2.195786714553833\n",
            "Epoch 60, Loss: 2.14143443107605\n",
            "Epoch 70, Loss: 2.092345952987671\n",
            "Epoch 80, Loss: 2.048044204711914\n",
            "Epoch 90, Loss: 2.0080714225769043\n",
            "Quantization levels: 8, Test Accuracy: 0.0\n",
            "Epoch 0, Loss: 2.3948025703430176\n",
            "Epoch 10, Loss: 2.34033465385437\n",
            "Epoch 20, Loss: 2.2914061546325684\n",
            "Epoch 30, Loss: 2.247500419616699\n",
            "Epoch 40, Loss: 2.2081081867218018\n",
            "Epoch 50, Loss: 2.1727423667907715\n",
            "Epoch 60, Loss: 2.1409482955932617\n",
            "Epoch 70, Loss: 2.112309694290161\n",
            "Epoch 80, Loss: 2.0864529609680176\n",
            "Epoch 90, Loss: 2.0630435943603516\n",
            "Quantization levels: 9, Test Accuracy: 0.0\n",
            "Epoch 0, Loss: 2.4050190448760986\n",
            "Epoch 10, Loss: 2.3612046241760254\n",
            "Epoch 20, Loss: 2.321446418762207\n",
            "Epoch 30, Loss: 2.2853493690490723\n",
            "Epoch 40, Loss: 2.2525429725646973\n",
            "Epoch 50, Loss: 2.2226827144622803\n",
            "Epoch 60, Loss: 2.1954567432403564\n",
            "Epoch 70, Loss: 2.1705832481384277\n",
            "Epoch 80, Loss: 2.1478118896484375\n",
            "Epoch 90, Loss: 2.1269192695617676\n",
            "Quantization levels: 10, Test Accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('Logistic_question.csv')\n",
        "\n",
        "# Preprocessing\n",
        "X = data.drop('Target', axis=1)\n",
        "y = data['Target']\n",
        "\n",
        "# Quantize the target column into i levels (change i from 2 to 10)\n",
        "for i in range(2, 11):\n",
        "    y_quantized = pd.qcut(y, i, labels=False)\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_quantized, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "    # Define and train the model\n",
        "    input_size = X.shape[1]\n",
        "    num_classes = len(np.unique(y_quantized))\n",
        "    model = MyMultinomialLogisticRegression(input_size, num_classes)\n",
        "\n",
        "    epochs = 100\n",
        "    lr = 0.01\n",
        "    model.fit(X_train, y_train, epochs, lr)\n",
        "\n",
        "    # Evaluate the model\n",
        "    with torch.no_grad():\n",
        "        predicted = model.predict(X_test)\n",
        "        accuracy = (predicted == y_test).sum().item() / len(y_test)\n",
        "        print(f'Quantization levels: {i}, Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of2sHl5Z4dXi"
      },
      "source": [
        "**Question:** Report for which $i$ your model performs best. Describe and analyze the results! You could use visualizations or any other method!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRLERDAr4wnS"
      },
      "source": [
        "**Your answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT43jGKV6CBZ"
      },
      "source": [
        "# Going a little further!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo9uGo0R6GZo"
      },
      "source": [
        "First we download Adult income dataset from Kaggle! In order to do this create an account on this website, and create an API. A file named kaggle.json will be downloaded to your device. Then use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "o-vrjYBF7u1E",
        "outputId": "7f2a6e24-0c8d-4e37-e893-21d856a2e130"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e9e9e165-98c0-49ea-9042-14453c48f76d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e9e9e165-98c0-49ea-9042-14453c48f76d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-900e0af62f3f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use this to select the kaggle.json file from your computer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir -p ~/.kaggle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cp kaggle.json ~/.kaggle/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chmod 600 ~/.kaggle/kaggle.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    157\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    158\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Use this to select the kaggle.json file from your computer\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i6u6_1v8ftX"
      },
      "source": [
        "Then use this code to automatically download the dataset into Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjyVaVKF29Hx"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d wenruliu/adult-income-dataset\n",
        "!unzip /content/adult-income-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXQnbZwt8rJK"
      },
      "source": [
        "**Task:** Determine the number of null entries!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtuEx6QW29c1"
      },
      "outputs": [],
      "source": [
        "# Your code goes here!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpEcBdTUAYVN"
      },
      "source": [
        "**Question:** In many widely used datasets there are a lot of null entries. Propose 5 methods by which, one could deal with this problem. Briefly explain how do you decide which one to use in this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1u1pBHuAsSg"
      },
      "source": [
        "**Your answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHhH-hkpAxFf"
      },
      "source": [
        "**Task:** Handle null entries using your best method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fVwWcjK29fk"
      },
      "outputs": [],
      "source": [
        "# Your code goes here!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43k5cTorCJaV"
      },
      "source": [
        "**Task:** Convert categorical features to numerical values. Split the dataset with 80-20 portion. Normalize all the data using X_train. Use the built-in Logistic Regression function and GridSearchCV to train your model, and report the parameters, train and test accuracy of the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Agj18Lcd-vyZ"
      },
      "outputs": [],
      "source": [
        "# Your code goes here!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lzr2lqXDQ1T"
      },
      "source": [
        "**Task:** To try a different route, split X_train into $i$ parts, and train $i$ separate models on these parts. Now propose and implement 3 different *ensemble methods* to derive the global models' prediction for X_test using the results(not necessarily predictions!) of the $i$ models. Firstly, set $i=10$ to find the method with the best test accuracy(the answer is not general!). You must Use your own Logistic Regression model.(You might want to modify it a little bit for this part!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9D1jlstF9nF"
      },
      "outputs": [],
      "source": [
        "# Your code goes here!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QS9HYJ5FW1T"
      },
      "source": [
        "**Question:** Explain your proposed methods and the reason you decided to use them!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hCBQuAeF46a"
      },
      "source": [
        "**Your answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjSREvg4FTHf"
      },
      "source": [
        "**Task:** Now, for your best method, change $i$ from 2 to 100 and report $i$, train and test accuracy of the best model. Also, plot test and train accuracy for $2\\leq i\\leq100$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfKS-Jq0-v4P"
      },
      "outputs": [],
      "source": [
        "# Your code goes here!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWV0YUgRGg1p"
      },
      "source": [
        "**Question:** Analyze the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlsoBt8sPUgC"
      },
      "source": [
        "**Your Answer:**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}